{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6VBOrJ4KBso"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUANmkjwJQJw"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten,Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.core import Dense # fully-connected net\n",
        "from keras import backend as K\n",
        "\n",
        "# simple cnn model on cifar10 small images dataset\n",
        "\n",
        "class Cnn:\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, classes):\n",
        "    # parameter: classes means the total number of classes we want to recognize\n",
        "    #initialize the model\n",
        "    model = Sequential()\n",
        "    inputShape = (height, width, depth)\n",
        "\n",
        "    # if we are using \"channel first\", update the input shape\n",
        "    # in some situation like TH, use channel first\n",
        "    if K.image_data_format() == \"channel_first\":\n",
        "      inputShape = (depth, height, width)\n",
        "\n",
        "    # first set of CONV => RELU => POOL layers => Dropout\n",
        "    # conv layer will learn 32 convolution filters, each of which are 3*3\n",
        "    model.add(Conv2D(32, (3, 3),padding = \"same\",input_shape = inputShape))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # second set of CONV => RELU => POOL layers => Dropout\n",
        "    model.add(Conv2D(64, (3, 3),padding = \"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # flattening out the volume into a set of fully-connected layer\n",
        "    # first and only set of FC => RELU laters\n",
        "    model.add(Flatten())\n",
        "    # fully-connected layer has 512 units\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # softmax classifier (output layer)\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    #return the constructed network architecture\n",
        "    return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qp7iQBODEU0",
        "outputId": "d48690e4-b7f7-413b-b6e4-980203c42394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Cnn.build(width=32, height=32, depth=3, classes=8)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 4104      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 1,249,832\n",
            "Trainable params: 1,249,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZLWwjn2LU3E"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_vectors():\n",
        "    vectors = {}\n",
        "    #f=open(\"glove.6B.50d.txt\")\n",
        "    f=open(\"glove.6B.300d.txt\")\n",
        "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck']\n",
        "    for i in f:\n",
        "        word = i.split()[0]\n",
        "        if word in classes:\n",
        "          vectors[word] = i.split()[1:]\n",
        "    return vectors"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKTMwhFFIyD_"
      },
      "source": [
        "# Real-time ploting\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class PlotLosses(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        \n",
        "        self.fig = plt.figure()\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        plt.show();\n",
        "        "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Ek3db6Lzos"
      },
      "source": [
        "# Training stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAn8tMW1K0YY",
        "outputId": "fc837991-c873-4800-b527-39bafbb50c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "\"\"\" \n",
        "we will do 4 things in this file\n",
        "1. Load image dataset from disk, get word vector\n",
        "2. Pre-process the images if needed\n",
        "3. Instantiate out convolutional neural network\n",
        "4. Train out image classifier getting top N classification probability of image\n",
        "5. Combine probability and word vector getting class of image\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "#from cnn import Cnn\n",
        "#import word_vector\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from keras.models import load_model\n",
        "\n",
        "# initialize the number of epochs to train for, initial learning rate and batch size\n",
        "batch_size = 32\n",
        "num_classes = 8\n",
        "epochs = 50\n",
        "optimizer = \"Adam\"\n",
        "data_augmentation = False\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_zsl_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# remove ship and truck class to get train data\n",
        "removed_indices = np.where(y_train!=8)[0]\n",
        "x_new_train = x_train[removed_indices]\n",
        "y_new_train = y_train[removed_indices]\n",
        "removed_indices = np.where(y_new_train!=9)[0]\n",
        "x_new_train = x_new_train[removed_indices]\n",
        "y_new_train = y_new_train[removed_indices]\n",
        "\n",
        "# remove ship and truck class to get validation data\n",
        "removed_indices = np.where(y_test!=8)[0]\n",
        "x_new_validation = x_test[removed_indices]\n",
        "y_new_validation = y_test[removed_indices]\n",
        "removed_indices = np.where(y_new_validation!=9)[0]\n",
        "x_new_validation = x_new_validation[removed_indices]\n",
        "y_new_validation = y_new_validation[removed_indices]\n",
        "\n",
        "# Convert class vectors to binary class matrices, like one-hot-encoding\n",
        "y_new_train = keras.utils.to_categorical(y_new_train,num_classes)\n",
        "y_new_validation = keras.utils.to_categorical(y_new_validation,num_classes)\n",
        "\n",
        "x_new_train = x_new_train.astype('float32')\n",
        "x_new_validation = x_new_validation.astype('float32')\n",
        "x_new_train /= 255\n",
        "x_new_validation /= 255\n",
        "\n",
        "plot_losses = PlotLosses()\n",
        "\n",
        "model = Cnn.build(width=32, height=32, depth=3, classes=8)\n",
        "\n",
        "if optimizer == \"rms\":\n",
        "  # initiate RMSprop optimizer\n",
        "  opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "else:\n",
        "  # initiate Adam optimizer\n",
        "  opt = keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "#  categorical_crossentropy\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_new_train, y_new_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_new_validation, y_new_validation),\n",
        "              callbacks=[plot_losses, callback],\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_new_train, y_new_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_new_validation, y_new_validation),\n",
        "                        workers=4)\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1250/1250 [==============================] - 179s 143ms/step - loss: 0.5136 - accuracy: 0.8152 - val_loss: 0.6794 - val_accuracy: 0.7738\n",
            "Saved trained model at /content/saved_models/keras_zsl_cifar10_trained_model.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE7_RB41HLuv"
      },
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    \"\"\"\n",
        "    Performs cosine similarity measure between two given vectors - v1 and v2, s.t. cosine_similarity = (v1.v2)/(||v1||.||v2||)\n",
        "\n",
        "    Arguments:\n",
        "    v1 -- a real-number vector\n",
        "    v2 -- a real-number vector\n",
        "\n",
        "    Returns:\n",
        "    cos -- the value of similarity between v1 and v2\n",
        "    \"\"\"\n",
        "    cos = (np.dot(v1,v2))/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
        "\n",
        "    return cos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6rnlY81Lv0c"
      },
      "source": [
        "# Test stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuhwxQkiLt4A",
        "outputId": "61efcc46-5082-41e4-a3a2-092d8f9e9bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "print(\"[INFO] loading network...\")\n",
        "model = load_model('saved_models/keras_zsl_cifar10_trained_model.h5')\n",
        "\n",
        "indices = np.where(y_test >= 8)[0]\n",
        "y_new_test = y_test[indices]\n",
        "x_new_test = x_test[indices]\n",
        "\n",
        "# combine probability got from cnn and word vector\n",
        "cnn_prob = model.predict(x_new_test)\n",
        "\n",
        "# get word vectors of seen classes\n",
        "embeddings = get_vectors()\n",
        "weights = []\n",
        "for i in class_labels[:-2]:\n",
        "  weights.append(embeddings[i])\n",
        "weights = np.array(weights,dtype=np.float32)\n",
        "\n",
        "# Predicted word embedding by convex combination\n",
        "cnn_embedding = np.dot(cnn_prob,weights)\n",
        "\n",
        "# Get all target_embeddings\n",
        "target_embeddings = []\n",
        "for i in class_labels:\n",
        "\ttarget_embeddings.append(embeddings[i])\n",
        "target_embeddings = np.array(target_embeddings, dtype=np.float32)\n",
        "\n",
        "# Use KNN to find the nearest class\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "n_samples = cnn_embedding.shape[0]\n",
        "\n",
        "# Calculate distance between the estimated representation and the projected prototypes\n",
        "dist = distance.cdist(cnn_embedding, target_embeddings, metric='cosine')\n",
        "# Get the index of min distances\n",
        "idx_min = np.argmin(dist, axis=1)\n",
        "# Get the labels of predictions\n",
        "preds = y_new_test[[i for i in idx_min]]\n",
        "\n",
        "# Calculate Top-1 accuracy\n",
        "diff = y_new_test - preds\n",
        "n_incorrect = len(np.nonzero(diff)[0])\n",
        "mean_accuracy = (n_samples - n_incorrect) / n_samples\n",
        "    \n",
        "print(\"Accuracy: %.2f%%\" % (mean_accuracy*100))\n",
        "#for i,j in zip(y_new_test, preds):\n",
        "#    print (i,j)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading network...\n",
            "Accuracy: 50.40%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}